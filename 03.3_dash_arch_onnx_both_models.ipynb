{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15da73890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, ctx\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dash import dash_table\n",
    "import onnxruntime as rt\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "model = rt.InferenceSession('model.onnx')\n",
    "ort_session = rt.InferenceSession('best.onnx')\n",
    "\n",
    "class_names = ['Modern', 'Palaty', 'Brutalism', 'Constructivism', 'Socialist_classicism', 'Industrial_XIX', 'Panelka', 'XXI_century', 'Classicism', 'Church', 'Fortification']\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Header(\n",
    "            \"This is app for recognition of architectural style of building by photo\",\n",
    "            style={\"font-size\": \"30px\", \"textAlign\": \"center\", 'font-family': 'Helvetica'},\n",
    "        ),\n",
    "    dcc.Upload(\n",
    "        id='upload-image',\n",
    "        children=html.Div([\n",
    "            'Drag and Drop or ',\n",
    "            html.A('Select File (the image will be croped automaticaly for recognition)')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '60%',\n",
    "            'height': '80px',\n",
    "            'lineHeight': '80px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px',\n",
    "            'font-family': 'Helvetica'\n",
    "        },\n",
    "        # Allow multiple files to be uploaded\n",
    "        multiple=False\n",
    "    ),\n",
    "    html.Div(id='output-image-upload'),\n",
    "    html.Div(id='output-prediction-text'),\n",
    "    html.Div(id='output-table-container')\n",
    "])\n",
    "\n",
    "\n",
    "# functions for onnx segmentation\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "  #  image = Image.open(image_path)\n",
    "    image = image_path.resize((640, 640))\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array.transpose(2, 0, 1)  # HWC to CHW\n",
    "    image_array = image_array / 255.0 \n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    image_array = image_array.astype(np.float32)\n",
    "    return image_array\n",
    "\n",
    "def run_inference(ort_session, image_path):\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "    output_name = ort_session.get_outputs()[0].name\n",
    "    \n",
    "    # Preprocess the image\n",
    "    input_data = preprocess_image(image_path)\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = ort_session.run([output_name], {input_name: input_data})[0]\n",
    "    return outputs\n",
    "\n",
    "def process_output(output, conf_threshold=0.1, iou_threshold=0.45):\n",
    "    boxes = []\n",
    "    for prediction in output[0]:\n",
    "        confidence = prediction[4]\n",
    "        if confidence >= conf_threshold:\n",
    "            x, y, w, h = prediction[:4]\n",
    "            class_id = np.argmax(prediction[5:])\n",
    "            boxes.append([x, y, w, h, confidence, class_id])\n",
    "    \n",
    "    # Apply Non-Maximum Suppression (NMS)\n",
    "    boxes = np.array(boxes)\n",
    "    indices = nms(boxes[:, :4], boxes[:, 4], iou_threshold)\n",
    "    return boxes[indices]\n",
    "\n",
    "def nms(bboxes, scores, iou_threshold):\n",
    "    x1 = bboxes[:, 0]\n",
    "    y1 = bboxes[:, 1]\n",
    "    x2 = x1 + bboxes[:, 2]\n",
    "    y2 = y1 + bboxes[:, 3]\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= iou_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "def draw_boxes(image_path, boxes, class_names):\n",
    "    #image = Image.open(image_path)\n",
    "    image = image_path.resize((640, 640))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box in boxes[:1]:\n",
    "        x, y, w, h, confidence, class_id = box\n",
    "        x1, y1 = int(x - w/2), int(y - h/2)\n",
    "        x2, y2 = int(x + w/2), int(y + h/2)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{class_names[int(class_id)]}: {confidence:.2f}\"\n",
    "        draw.text((x1, y1 - 10), label, fill=\"red\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "def crop_image(image_path, box):\n",
    "   # image = Image.open(image_path)\n",
    "    image = image_path.resize((640, 640))\n",
    "    x, y, w, h = box[:4]\n",
    "    x1, y1 = int(x - w/2), int(y - h/2)\n",
    "    x2, y2 = int(x + w/2), int(y + h/2)\n",
    "    cropped_image = image.crop((x1, y1, x2, y2))\n",
    "    return cropped_image\n",
    "\n",
    "def resize_image_pil(img):\n",
    "    # Convert the image string to PIL Image\n",
    "    img = Image.open(io.BytesIO(base64.b64decode(img.split(\",\")[1])))  #.convert('L')\n",
    "    img = img.convert(\"RGB\")\n",
    "    try:\n",
    "        cropped_img = crop_image(img, process_output(run_inference(ort_session, img))[0])\n",
    "        imag_bbox = cropped_img\n",
    "        imag_bbox = draw_boxes(img, process_output(run_inference(ort_session, img)), 'building')\n",
    "        crop_fact = 'Successful detection. Returning cropped image.'\n",
    "    except:\n",
    "        img = img.resize((640, 640))\n",
    "        cropped_img = img\n",
    "        imag_bbox = img\n",
    "        crop_fact = 'There is no building detected, probably style in table below. Returning uncropped image.'\n",
    "   \n",
    "    return cropped_img, imag_bbox, crop_fact\n",
    "\n",
    "def process_and_predict(image_string):\n",
    "    cropped_img, imag_bbox, crop_fact = resize_image_pil(image_string)\n",
    "    \n",
    "    # Load pre-trained model\n",
    "    #model = load_model(export_path)  \n",
    "    \n",
    "    # Perform prediction using the model\n",
    "    img_resized = cropped_img.resize((256, 256))\n",
    "    img_resized = img_resized.convert('L')\n",
    "    img_resized = img_resized.convert(\"RGB\")\n",
    "    img_resized = np.array(img_resized)\n",
    "    a = np.expand_dims(img_resized / 255.0, axis=0).astype(np.float32)\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    output_name = model.get_outputs()[0].name\n",
    "    pred = model.run([output_name], {input_name: a.astype(np.float32)})[0]\n",
    "    #prediction = model.predict(np.expand_dims(img_resized / 255.0, axis=0))\n",
    "    \n",
    "    class_name = []\n",
    "    probability = []\n",
    "\n",
    "    for i in np.argsort(pred, axis=1)[:, -3:][0][::-1]:\n",
    "        class_name.append(class_names[i]) \n",
    "        probability.append(str(np.round(pred[0][i],2))) \n",
    "\n",
    "    class_idx = pd.DataFrame({'Style': class_name, 'Probability': probability})    \n",
    "\n",
    "    return class_idx, cropped_img, imag_bbox, crop_fact # Return the predicted class index\n",
    "\n",
    "def pil_image_to_base64(img):\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return f\"data:image/png;base64,{img_str}\"\n",
    "\n",
    "@app.callback(Output('output-image-upload', 'children'),\n",
    "              Output('output-table-container', 'children'),\n",
    "              Output('output-prediction-text', 'children'),\n",
    "              Input('upload-image', 'contents'), prevent_initial_call=True)\n",
    "\n",
    "def update_output(contents):\n",
    "    if contents is not None:\n",
    "        # Process image and get prediction\n",
    "        df, cropped_img, imag_bbox, crop_fact = process_and_predict(contents)\n",
    "        \n",
    "        # Convert the cropped image to base64\n",
    "        cropped_img_base64 = pil_image_to_base64(imag_bbox)\n",
    "        \n",
    "        # Display cropped image\n",
    "        children_img = html.Div([\n",
    "            html.Img(src=cropped_img_base64, style={'width': '320px', 'height': '320px'}),\n",
    "            html.Hr(),\n",
    "            html.Div(id='output-prediction')\n",
    "        ])\n",
    "        \n",
    "        # Create a table for the prediction results\n",
    "        table = dash_table.DataTable(\n",
    "            id='table',\n",
    "            columns=[{'name': col, 'id': col} for col in df.columns],\n",
    "            data=df.to_dict('records'),\n",
    "                style_table={'textAlign': 'left', 'height': '150px', 'overflowY': 'auto', 'width': '350px', 'font-family': 'Helvetica'},\n",
    "                style_cell={'textAlign': 'left', 'font-family': 'Helvetica'}\n",
    "        )\n",
    "        text_phrase = html.Div(crop_fact, style={'font-size': '20px', 'color': 'black', 'font-family': 'Helvetica'})\n",
    "        # Return the updated image and prediction table\n",
    "        return children_img, table, text_phrase\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, host='0.0.0.0', port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
