{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9f7e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladkozlovskiy/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-9-3 Python-3.11.7 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x36a902150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import dash\n",
    "from dash import Dash, dcc, html, Input, Output, ctx\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dash import dash_table\n",
    "from tensorflow.keras.models import load_model  \n",
    "\n",
    "import torch\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "export_path = 'model_final_sept'\n",
    "detect = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt')  \n",
    "\n",
    "class_names = ['Modern', 'Palaty', 'Brutalism', 'Constructivism', 'Socialist_classicism', 'Industrial_XIX', 'Panelka', 'XXI_century', 'Classicism', 'Church', 'Fortification']\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Header(\n",
    "            \"This is app for recognition of architectural style of building by photo\",\n",
    "            style={\"font-size\": \"30px\", \"textAlign\": \"center\", 'font-family': 'Helvetica'},\n",
    "        ),\n",
    "    dcc.Upload(\n",
    "        id='upload-image',\n",
    "        children=html.Div([\n",
    "            'Drag and Drop or ',\n",
    "            html.A('Select File (the image will be croped automaticaly for recognition)')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '60%',\n",
    "            'height': '80px',\n",
    "            'lineHeight': '80px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px',\n",
    "            'font-family': 'Helvetica'\n",
    "        },\n",
    "        # Allow multiple files to be uploaded\n",
    "        multiple=False\n",
    "    ),\n",
    "    html.Div(id='output-image-upload'),\n",
    "    html.Div(id='output-prediction-text'),\n",
    "    html.Div(id='output-table-container')\n",
    "])\n",
    "\n",
    "def crop_building(image, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    return image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "def draw_boxes(image_path, boxes, class_names):\n",
    "    #image = image_path.resize((640, 640))\n",
    "    image = image_path\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box in boxes[:1]:\n",
    "\n",
    "        x, y, w, h, confidence, class_id = box\n",
    "      #  x1, y1 = int(x - w/2), int(y - h/2)\n",
    "      #  x2, y2 = int(x + w/2), int(y + h/2)\n",
    "        x1, y1, x2, y2 = x, y, w, h\n",
    "\n",
    "        # Draw rectangle\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{class_names[int(class_id)]}: {confidence:.2f}\"\n",
    "        draw.text((x1, y1 - 10), label, fill=\"red\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "def resize_image_pil(img):\n",
    "    # Convert the image string to PIL Image\n",
    "    img = Image.open(io.BytesIO(base64.b64decode(img.split(\",\")[1])))  #.convert('L')\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    results = detect(img)\n",
    "    check_detection = list(results.xyxy[0].numpy())\n",
    "\n",
    "\n",
    "    if not check_detection:\n",
    "        crop_fact = 'There is no building detected, probably style in table below. Returning uncropped image.'\n",
    "\n",
    "        img = img.resize((640, 640))\n",
    "        cropped_img = img\n",
    "        imag_bbox = img\n",
    "\n",
    "    else:\n",
    "        crop_fact = 'Successful detection. Returning cropped image.'\n",
    "\n",
    "        for bbox in results.xyxy[0].numpy():\n",
    "\n",
    "            x_min, y_min, x_max, y_max, confidence, class_id = bbox\n",
    "\n",
    "            x_min, y_min, x_max, y_max = map(int, [x_min, y_min, x_max, y_max])\n",
    "\n",
    "            # Crop the building\n",
    "            cropped_img = crop_building(img, (x_min, y_min, x_max, y_max))\n",
    "            imag_bbox = draw_boxes(img, results.xyxy[0].numpy(), 'building')\n",
    "\n",
    "    imag_bbox = imag_bbox.resize((640, 640))\n",
    "  \n",
    "    return cropped_img, imag_bbox, crop_fact\n",
    "\n",
    "def process_and_predict(image_string):\n",
    "    cropped_img, imag_bbox, crop_fact = resize_image_pil(image_string)\n",
    "    \n",
    "    # Load pre-trained model\n",
    "    model = load_model(export_path)  \n",
    "    \n",
    "    img_resized = cropped_img.resize((256, 256))\n",
    "    img_resized = img_resized.convert('L')\n",
    "    img_resized = img_resized.convert(\"RGB\")\n",
    "    img_resized = np.array(img_resized)\n",
    "\n",
    "    # Perform prediction using the model\n",
    "    prediction = model.predict(np.expand_dims(img_resized / 255.0, axis=0))\n",
    "    \n",
    "    class_name = []\n",
    "    probability = []\n",
    "\n",
    "    for i in np.argsort(prediction, axis=1)[:, -3:]:\n",
    "        [class_name.append(class_names[x]) for x in reversed(i)]\n",
    "        [probability.append(str(np.round(prediction[0][x],2))) for x in reversed(i)]   \n",
    "\n",
    "    class_idx = pd.DataFrame({'Style': class_name, 'Probability': probability})    \n",
    "\n",
    "    return class_idx, cropped_img, imag_bbox, crop_fact  # Return the predicted class index\n",
    "\n",
    "def pil_image_to_base64(img):\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return f\"data:image/png;base64,{img_str}\"\n",
    "\n",
    "@app.callback(Output('output-image-upload', 'children'),\n",
    "              Output('output-table-container', 'children'),\n",
    "              Output('output-prediction-text', 'children'),\n",
    "              Input('upload-image', 'contents'), prevent_initial_call=True)\n",
    "\n",
    "def update_output(contents):\n",
    "    if contents is not None:\n",
    "        # Process image and get prediction\n",
    "        df, cropped_img, imag_bbox, crop_fact = process_and_predict(contents)\n",
    "        \n",
    "        # Convert the cropped image to base64\n",
    "        cropped_img_base64 = pil_image_to_base64(imag_bbox)\n",
    "        \n",
    "        # Display cropped image\n",
    "        children_img = html.Div([\n",
    "            html.Img(src=cropped_img_base64, style={'width': '320px', 'height': '320px'}),\n",
    "            html.Hr(),\n",
    "            html.Div(id='output-prediction')\n",
    "        ])\n",
    "        \n",
    "        # Create a table for the prediction results\n",
    "        table = dash_table.DataTable(\n",
    "            id='table',\n",
    "            columns=[{'name': col, 'id': col} for col in df.columns],\n",
    "            data=df.to_dict('records'),\n",
    "                style_table={'textAlign': 'left', 'height': '150px', 'overflowY': 'auto', 'width': '350px', 'font-family': 'Helvetica'},\n",
    "                style_cell={'textAlign': 'left', 'font-family': 'Helvetica'}\n",
    "        )\n",
    "        text_phrase = html.Div(crop_fact, style={'font-size': '20px', 'color': 'black', 'font-family': 'Helvetica'})\n",
    "        # Return the updated image and prediction table\n",
    "        return children_img, table, text_phrase\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, host='0.0.0.0', port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121aa0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
